{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VGG-like_DataAugmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR4tIXGDecnu"
      },
      "source": [
        "<h1> Image Classification using Data Augmentation on VGG-like architecture</h1>\r\n",
        "\r\n",
        "Image Classification helps us in taking important decisions. But the data is not always availaible hence the model we learn dont learn feature efficiently and are prone to over-fitting. Hence it is need of the hour to apply techniques such as Data Augmentation that increases the amount of data and allow model to learn variations that were not employed before. VGG-like architecture is used to use the concept of Data Augmentation\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFKR1D60S8r5"
      },
      "source": [
        "# necessary imports\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.datasets import load_files\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from imutils import paths\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from tqdm import tqdm\r\n",
        "import collections\r\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling2D\r\n",
        "from keras.optimizers import Adam, SGD, RMSprop\r\n",
        "import keras\r\n",
        "from keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Dropout\r\n",
        "from keras.models import Sequential\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import datetime\r\n",
        "import glob as glob\r\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n",
        "from keras.optimizers import SGD\r\n",
        "import tensorflow\r\n",
        "import pandas as pd\r\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\r\n",
        "from skimage import feature\r\n",
        "from skimage import exposure\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from google.colab import files\r\n",
        "from keras.models import load_model\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezvdRvHQfVGb"
      },
      "source": [
        "<h2> Load Dataset </h2>\r\n",
        "Here we will download the Dataset of Natural Scene from kaggel intel-image-classification and unzip it in local colab directory <br><br>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "VaKV0MDB1PEm",
        "outputId": "36b12813-8070-4ebb-84cf-6dedc6137a3a"
      },
      "source": [
        "#Uploading kaggle.json file\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ec54d755-bcde-4b79-b1b4-58666eddd8d3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ec54d755-bcde-4b79-b1b4-58666eddd8d3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aamna27\",\"key\":\"9944f09a800fd209ebde42468fb6f834\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP4JIA0szHdq"
      },
      "source": [
        "! mkdir ~/.kaggle\r\n",
        "! cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpvessaQ228r",
        "outputId": "9ab0cb3b-d839-47ca-d3c6-b0dc4f0a557a"
      },
      "source": [
        "!kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading intel-image-classification.zip to /content\n",
            " 97% 337M/346M [00:01<00:00, 241MB/s]\n",
            "100% 346M/346M [00:01<00:00, 237MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZUfvjq0CgtQ"
      },
      "source": [
        "!unzip intel-image-classification.zip -d Dataset\r\n",
        "!rm -rf /content/intel-image-classification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5YzkTXIVWE2"
      },
      "source": [
        "!rm -rf /content/Dataset/seg_pred\r\n",
        "!unzip Test_data.zip -d Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as51uanugGqw"
      },
      "source": [
        "train_dir = 'Dataset/seg_train/seg_train'\r\n",
        "validate_dir = 'Dataset/seg_test/seg_test'\r\n",
        "test_dir = 'Dataset/seg_pred/seg_pred'\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "nb_classes = len(glob.glob(train_dir + '/*'))\r\n",
        "\r\n",
        "# get number of images in training directory\r\n",
        "nb_train_samples = 0\r\n",
        "for r, dirs, files in os.walk(train_dir):\r\n",
        "    for dr in dirs:\r\n",
        "        nb_train_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))\r\n",
        "# get number of images in validation directory\r\n",
        "nb_validate_samples = 0\r\n",
        "for r, dirs, files in os.walk(validate_dir):\r\n",
        "    for dr in dirs:\r\n",
        "        nb_validate_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))\r\n",
        "\r\n",
        "nb_test_samples = 0\r\n",
        "for r, dirs, files in os.walk(test_dir):\r\n",
        "    for dr in dirs:\r\n",
        "        nb_test_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmTs3sLA210H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzTT7T00ghCD"
      },
      "source": [
        "Making dictionary to store results of experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTjQfsgEw99v"
      },
      "source": [
        "\r\n",
        "all_acc_dict = collections.OrderedDict()\r\n",
        "accdict = {}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMNXIlQ7f72c"
      },
      "source": [
        "<h2> Data Augmentation </h2>\r\n",
        "Data preparation is almost always required when working with any data analysis, machine learning, neural network or deep learning models. It becomes even more important to augment data in the case of image recognition. Keras provides the ImageDataGenerator class that defines the configuration for image data preparation and augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_yZUSYgNggC"
      },
      "source": [
        "\r\n",
        "nb_epochs = 20\r\n",
        "batch_size = 32\r\n",
        "# data pre-processing for training\r\n",
        "train_datagen =  ImageDataGenerator(\r\n",
        "    rescale = 1./255,\r\n",
        "    rotation_range = 20,\r\n",
        "    width_shift_range = 0.2,\r\n",
        "    height_shift_range = 0.2,\r\n",
        "    shear_range = 0.2,\r\n",
        "    fill_mode = 'nearest',\r\n",
        "    horizontal_flip = True)\r\n",
        "\r\n",
        "# data pre-processing for validation\r\n",
        "validate_datagen =  ImageDataGenerator(\r\n",
        "    rescale = 1./255,\r\n",
        "    rotation_range = 20,\r\n",
        "    width_shift_range = 0.2,\r\n",
        "    height_shift_range = 0.2,\r\n",
        "    shear_range = 0.2,\r\n",
        "    fill_mode = 'nearest',\r\n",
        "    horizontal_flip = True)\r\n",
        "# data pre-processing for validation\r\n",
        "test_datagen =  ImageDataGenerator(\r\n",
        "    rescale = 1./255,\r\n",
        "    rotation_range = 20,\r\n",
        "    width_shift_range = 0.2,\r\n",
        "    height_shift_range = 0.2,\r\n",
        "    shear_range = 0.2,\r\n",
        "    # zoom_range = 0.2,\r\n",
        "    fill_mode = 'nearest',\r\n",
        "    horizontal_flip = True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYZbKFo3N43u",
        "outputId": "3cbc6a51-108d-444c-9a6a-798e3efe0d36"
      },
      "source": [
        "# generate and store training data\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    train_dir,\r\n",
        "    target_size = (32, 32),\r\n",
        "    batch_size = batch_size)\r\n",
        "\r\n",
        "# generate and store validation data\r\n",
        "validate_generator = validate_datagen.flow_from_directory(\r\n",
        "    validate_dir,\r\n",
        "    target_size = (32, 32),\r\n",
        "    batch_size = batch_size)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(\r\n",
        "    test_dir,\r\n",
        "    target_size = (32, 32),\r\n",
        "    batch_size = batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14034 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n",
            "Found 7301 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhugA8KTjB1-"
      },
      "source": [
        "<h2> VGG-Like Architecture </h2>\r\n",
        "Architecture build on VGG style is being used here. Since original architecture was very complex, few layers have been removed based on problem at hand. Instead of 224*224*3, input shape of 32*32*3 has been used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uirlE7gzM0a0"
      },
      "source": [
        "def VGG16model(OPTIMIZER, DECAY, MOMEMTUM, LEARN_RATE, EPOCHS, INPUT_SHAPE_WIDTH = 32, \r\n",
        "               INPUT_SHAPE_HEIGHT = 32, INPUT_SHAPE_CHANNEL = 3):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", \r\n",
        "                  input_shape=(INPUT_SHAPE_WIDTH,INPUT_SHAPE_HEIGHT,INPUT_SHAPE_CHANNEL),))\r\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\r\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "\r\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "\r\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "  model.add(Flatten())\r\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\r\n",
        "  model.add(Dense(units=6, activation=\"softmax\"))\r\n",
        "\r\n",
        "  if OPTIMIZER == \"Adam\":\r\n",
        "    print(OPTIMIZER)\r\n",
        "    LEARN_RATE = 0.001/EPOCHS  #in case you want to manually set fix lr\r\n",
        "    adam = Adam(lr=LEARN_RATE)\r\n",
        "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=adam)\r\n",
        "\r\n",
        "  if OPTIMIZER == \"SGD\":\r\n",
        "    print(OPTIMIZER)\r\n",
        "    LEARN_RATE = 0.001/EPOCHS  #in case you want to manually set fix lr\r\n",
        "    sgd = SGD(lr=LEARN_RATE) \r\n",
        "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=sgd)\r\n",
        "\r\n",
        "  if OPTIMIZER == \"RMS\":\r\n",
        "    print(OPTIMIZER)\r\n",
        "    LEARN_RATE = 0.001/EPOCHS  #in case you want to manually set fix lr\r\n",
        "    rms = RMSprop(lr=LEARN_RATE)\r\n",
        "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=rms)\r\n",
        "  return (model)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJNgm7E2PYdQ"
      },
      "source": [
        "\r\n",
        "vgg_model_pic = VGG16model(\"Adam\", DECAY= 1e-7, MOMEMTUM = 0.9, LEARN_RATE =0.001, EPOCHS =75)\r\n",
        "plot_model(vgg_model_pic, to_file='Results/VGG-like-model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ux5l-EGjhTQ"
      },
      "source": [
        "<h2> Compile and Train the Model </h2>\r\n",
        "Using different choices of optimizers, the model is being trained. **Early Stopping** is being used to tackle number of epochs. Each time a better validation accuracy is achieved the model weights are updated in the directory.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BdAcr4Cwef9"
      },
      "source": [
        "\r\n",
        "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\r\n",
        "mc = ModelCheckpoint('CheckPoints/VGG-like-Aug-model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\r\n",
        "\r\n",
        "def training(BATCH_SIZE, EPOCHS, OPTIMIZER, LEARN_RATE, DECAY = 0, MOMEMTUM = 0 ):\r\n",
        "  # accdict = {}\r\n",
        "  vgg_model = VGG16model(OPTIMIZER, DECAY, MOMEMTUM, LEARN_RATE, EPOCHS)\r\n",
        "  H = vgg_model.fit_generator(\r\n",
        "    train_generator,\r\n",
        "    epochs = EPOCHS,\r\n",
        "    validation_data = validate_generator,\r\n",
        "    callbacks=[es,mc])\r\n",
        "  trainacc = H.history['accuracy']\r\n",
        "  valacc = H.history['val_accuracy']\r\n",
        "  trainloss = H.history['loss']\r\n",
        "  valloss = H.history['val_loss']\r\n",
        "  score = vgg_model.evaluate_generator(test_generator)\r\n",
        "  accdict[\"trainacc\"] =trainacc[len(trainacc)-1]\r\n",
        "  accdict[\"trainloss\"] =trainloss[len(trainloss)-1]\r\n",
        "  accdict[\"valacc\"] = valacc[len(valacc)-1]\r\n",
        "  accdict[\"valloss\"] = valloss[len(valloss)-1]\r\n",
        "  accdict[\"testacc\"] = score[1]\r\n",
        "  accdict[\"testloss\"] = score[0]\r\n",
        "  \r\n",
        "  return H, accdict"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSixzD6-xGlj",
        "outputId": "03138445-f1c9-4baa-e736-08a78f27a0b5"
      },
      "source": [
        "\r\n",
        "History1, all_acc_dict[\"Adam_Exp1\"] = training(32, 75, \"Adam\", 0.001)\r\n",
        "History2, all_acc_dict[\"Adam_Exp2\"] = training(64, 75, \"Adam\", 0.001)\r\n",
        "History3, all_acc_dict[\"Adam_Exp3\"] = training(128, 75,\"Adam\", 0.001) \r\n",
        "\r\n",
        "History4, all_acc_dict[\"SGD_Exp1\"] = training(32, 75, \"SGD\", 0.001)\r\n",
        "History5, all_acc_dict[\"SGD_Exp2\"] = training(64, 75, \"SGD\", 0.001)\r\n",
        "History6, all_acc_dict[\"SGD_Exp3\"] = training(128, 75,\"SGD\", 0.001) \r\n",
        "\r\n",
        "History7, all_acc_dict[\"RMS_Exp1\"] = training(32, 75, \"RMS\", 0.001)\r\n",
        "History8, all_acc_dict[\"RMS_Exp2\"] = training(64, 75, \"RMS\", 0.001)\r\n",
        "History9, all_acc_dict[\"RMS_Exp3\"] = training(128, 75,\"RMS\", 0.001) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "439/439 [==============================] - 31s 54ms/step - loss: 1.7469 - accuracy: 0.2232 - val_loss: 1.3619 - val_accuracy: 0.4447\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.44467, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 2/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.3077 - accuracy: 0.4823 - val_loss: 1.2913 - val_accuracy: 0.4703\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.44467 to 0.47033, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 3/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.2022 - accuracy: 0.5210 - val_loss: 1.2557 - val_accuracy: 0.4927\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.47033 to 0.49267, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 4/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.1480 - accuracy: 0.5433 - val_loss: 1.2273 - val_accuracy: 0.5067\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.49267 to 0.50667, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 5/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.0958 - accuracy: 0.5545 - val_loss: 1.2439 - val_accuracy: 0.5023\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.50667\n",
            "Epoch 6/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.0682 - accuracy: 0.5733 - val_loss: 1.2085 - val_accuracy: 0.5190\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.50667 to 0.51900, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 7/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.0537 - accuracy: 0.5817 - val_loss: 1.1867 - val_accuracy: 0.5253\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.51900 to 0.52533, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 8/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.0194 - accuracy: 0.6005 - val_loss: 1.1947 - val_accuracy: 0.5290\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.52533 to 0.52900, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 9/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.0118 - accuracy: 0.6129 - val_loss: 1.2016 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.52900 to 0.53700, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 10/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.9674 - accuracy: 0.6236 - val_loss: 1.1398 - val_accuracy: 0.5537\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.53700 to 0.55367, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 11/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9494 - accuracy: 0.6276 - val_loss: 1.1762 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.55367\n",
            "Epoch 12/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9342 - accuracy: 0.6340 - val_loss: 1.0773 - val_accuracy: 0.5910\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.55367 to 0.59100, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 13/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9170 - accuracy: 0.6445 - val_loss: 1.0829 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.59100\n",
            "Epoch 14/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 0.9054 - accuracy: 0.6561 - val_loss: 1.0257 - val_accuracy: 0.6050\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.59100 to 0.60500, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 15/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9119 - accuracy: 0.6504 - val_loss: 1.0984 - val_accuracy: 0.5883\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.60500\n",
            "Epoch 16/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8812 - accuracy: 0.6646 - val_loss: 1.0319 - val_accuracy: 0.6053\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.60500 to 0.60533, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 17/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8770 - accuracy: 0.6649 - val_loss: 1.1065 - val_accuracy: 0.5873\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.60533\n",
            "Epoch 18/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8947 - accuracy: 0.6553 - val_loss: 0.9687 - val_accuracy: 0.6313\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.60533 to 0.63133, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 19/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8579 - accuracy: 0.6712 - val_loss: 1.0593 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.63133\n",
            "Epoch 20/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8466 - accuracy: 0.6663 - val_loss: 0.9249 - val_accuracy: 0.6467\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.63133 to 0.64667, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 21/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8374 - accuracy: 0.6806 - val_loss: 1.0005 - val_accuracy: 0.6257\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.64667\n",
            "Epoch 22/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8334 - accuracy: 0.6815 - val_loss: 0.9526 - val_accuracy: 0.6437\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.64667\n",
            "Epoch 23/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8217 - accuracy: 0.6850 - val_loss: 0.9519 - val_accuracy: 0.6397\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.64667\n",
            "Epoch 24/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8181 - accuracy: 0.6913 - val_loss: 1.1376 - val_accuracy: 0.6030\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.64667\n",
            "Epoch 25/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8173 - accuracy: 0.6906 - val_loss: 0.9399 - val_accuracy: 0.6550\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.64667 to 0.65500, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 00025: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Adam\n",
            "Epoch 1/75\n",
            "439/439 [==============================] - 24s 53ms/step - loss: 1.7488 - accuracy: 0.2284 - val_loss: 1.3919 - val_accuracy: 0.4493\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.65500\n",
            "Epoch 2/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 1.3311 - accuracy: 0.4812 - val_loss: 1.2894 - val_accuracy: 0.4747\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.65500\n",
            "Epoch 3/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.2430 - accuracy: 0.5128 - val_loss: 1.2052 - val_accuracy: 0.5240\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.65500\n",
            "Epoch 4/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.1530 - accuracy: 0.5416 - val_loss: 1.2142 - val_accuracy: 0.4907\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.65500\n",
            "Epoch 5/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.1098 - accuracy: 0.5581 - val_loss: 1.2645 - val_accuracy: 0.4823\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.65500\n",
            "Epoch 6/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.0684 - accuracy: 0.5782 - val_loss: 1.1312 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.65500\n",
            "Epoch 7/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.0425 - accuracy: 0.5859 - val_loss: 1.1036 - val_accuracy: 0.5680\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.65500\n",
            "Epoch 8/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.0251 - accuracy: 0.6000 - val_loss: 1.0849 - val_accuracy: 0.5787\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.65500\n",
            "Epoch 9/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.0007 - accuracy: 0.6055 - val_loss: 1.0838 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.65500\n",
            "Epoch 10/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.9827 - accuracy: 0.6232 - val_loss: 1.0459 - val_accuracy: 0.6063\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.65500\n",
            "Epoch 11/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.9730 - accuracy: 0.6220 - val_loss: 1.0947 - val_accuracy: 0.5790\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.65500\n",
            "Epoch 12/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 0.9566 - accuracy: 0.6310 - val_loss: 1.0417 - val_accuracy: 0.6057\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.65500\n",
            "Epoch 13/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 0.9474 - accuracy: 0.6327 - val_loss: 1.1109 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.65500\n",
            "Epoch 14/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.9194 - accuracy: 0.6453 - val_loss: 0.9986 - val_accuracy: 0.6260\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.65500\n",
            "Epoch 15/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8998 - accuracy: 0.6507 - val_loss: 1.0170 - val_accuracy: 0.6073\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.65500\n",
            "Epoch 16/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8868 - accuracy: 0.6543 - val_loss: 0.9724 - val_accuracy: 0.6400\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.65500\n",
            "Epoch 17/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 0.8785 - accuracy: 0.6578 - val_loss: 1.0353 - val_accuracy: 0.6130\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.65500\n",
            "Epoch 18/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8839 - accuracy: 0.6601 - val_loss: 0.8962 - val_accuracy: 0.6590\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.65500 to 0.65900, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 19/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8620 - accuracy: 0.6709 - val_loss: 1.0103 - val_accuracy: 0.6193\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.65900\n",
            "Epoch 20/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.8456 - accuracy: 0.6826 - val_loss: 0.9061 - val_accuracy: 0.6663\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.65900 to 0.66633, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 21/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.8337 - accuracy: 0.6877 - val_loss: 0.9248 - val_accuracy: 0.6550\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.66633\n",
            "Epoch 22/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8149 - accuracy: 0.6878 - val_loss: 0.8887 - val_accuracy: 0.6687\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.66633 to 0.66867, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 23/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 0.8074 - accuracy: 0.6916 - val_loss: 0.8990 - val_accuracy: 0.6690\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.66867 to 0.66900, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 24/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8130 - accuracy: 0.6942 - val_loss: 0.8782 - val_accuracy: 0.6793\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.66900 to 0.67933, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 25/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.8023 - accuracy: 0.6962 - val_loss: 0.8861 - val_accuracy: 0.6727\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.67933\n",
            "Epoch 26/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.7968 - accuracy: 0.7005 - val_loss: 0.8591 - val_accuracy: 0.6790\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.67933\n",
            "Epoch 27/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7982 - accuracy: 0.7006 - val_loss: 1.0002 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.67933\n",
            "Epoch 28/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.7703 - accuracy: 0.7091 - val_loss: 0.8523 - val_accuracy: 0.6957\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.67933 to 0.69567, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 29/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 0.7687 - accuracy: 0.7133 - val_loss: 0.8546 - val_accuracy: 0.6853\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.69567\n",
            "Epoch 30/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7617 - accuracy: 0.7177 - val_loss: 0.8760 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.69567\n",
            "Epoch 31/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7713 - accuracy: 0.7079 - val_loss: 0.8394 - val_accuracy: 0.6890\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.69567\n",
            "Epoch 32/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7474 - accuracy: 0.7192 - val_loss: 0.8668 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.69567\n",
            "Epoch 33/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7460 - accuracy: 0.7267 - val_loss: 0.8147 - val_accuracy: 0.7007\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.69567 to 0.70067, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 34/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7500 - accuracy: 0.7166 - val_loss: 0.8322 - val_accuracy: 0.7010\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.70067 to 0.70100, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 35/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.7385 - accuracy: 0.7230 - val_loss: 0.8299 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.70100 to 0.70267, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 36/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7177 - accuracy: 0.7310 - val_loss: 0.7971 - val_accuracy: 0.7040\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.70267 to 0.70400, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 37/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 0.7298 - accuracy: 0.7204 - val_loss: 0.8737 - val_accuracy: 0.6830\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.70400\n",
            "Epoch 38/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 0.7271 - accuracy: 0.7288 - val_loss: 0.8098 - val_accuracy: 0.6960\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.70400\n",
            "Epoch 39/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7160 - accuracy: 0.7325 - val_loss: 0.8207 - val_accuracy: 0.6980\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.70400\n",
            "Epoch 40/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7133 - accuracy: 0.7332 - val_loss: 0.8065 - val_accuracy: 0.7077\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.70400 to 0.70767, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 41/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.7136 - accuracy: 0.7334 - val_loss: 0.8087 - val_accuracy: 0.7127\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.70767 to 0.71267, saving model to CheckPoints/VGG-like-Aug-model.h5\n",
            "Epoch 00041: early stopping\n",
            "Adam\n",
            "Epoch 1/75\n",
            "439/439 [==============================] - 24s 52ms/step - loss: 1.7539 - accuracy: 0.2300 - val_loss: 1.4179 - val_accuracy: 0.4220\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.71267\n",
            "Epoch 2/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.3509 - accuracy: 0.4811 - val_loss: 1.2859 - val_accuracy: 0.4730\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.71267\n",
            "Epoch 3/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.2258 - accuracy: 0.5130 - val_loss: 1.2649 - val_accuracy: 0.4697\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.71267\n",
            "Epoch 4/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.1565 - accuracy: 0.5434 - val_loss: 1.2431 - val_accuracy: 0.5033\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71267\n",
            "Epoch 5/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.1216 - accuracy: 0.5542 - val_loss: 1.2588 - val_accuracy: 0.5103\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71267\n",
            "Epoch 6/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.1008 - accuracy: 0.5625 - val_loss: 1.4198 - val_accuracy: 0.4843\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71267\n",
            "Epoch 7/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.0579 - accuracy: 0.5802 - val_loss: 1.2344 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71267\n",
            "Epoch 8/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.0391 - accuracy: 0.5904 - val_loss: 1.4322 - val_accuracy: 0.4833\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71267\n",
            "Epoch 9/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.0239 - accuracy: 0.6002 - val_loss: 1.3789 - val_accuracy: 0.4990\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71267\n",
            "Epoch 10/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9994 - accuracy: 0.6205 - val_loss: 1.2866 - val_accuracy: 0.5193\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71267\n",
            "Epoch 11/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9859 - accuracy: 0.6166 - val_loss: 1.3201 - val_accuracy: 0.5187\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71267\n",
            "Epoch 12/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 0.9740 - accuracy: 0.6206 - val_loss: 1.3084 - val_accuracy: 0.5190\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71267\n",
            "Epoch 00012: early stopping\n",
            "SGD\n",
            "Epoch 1/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7930 - accuracy: 0.1666 - val_loss: 1.7919 - val_accuracy: 0.1487\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.71267\n",
            "Epoch 2/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7936 - accuracy: 0.1634 - val_loss: 1.7920 - val_accuracy: 0.1407\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.71267\n",
            "Epoch 3/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7937 - accuracy: 0.1610 - val_loss: 1.7919 - val_accuracy: 0.1437\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.71267\n",
            "Epoch 4/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7933 - accuracy: 0.1633 - val_loss: 1.7918 - val_accuracy: 0.1493\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71267\n",
            "Epoch 5/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7934 - accuracy: 0.1632 - val_loss: 1.7918 - val_accuracy: 0.1433\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71267\n",
            "Epoch 6/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7932 - accuracy: 0.1614 - val_loss: 1.7918 - val_accuracy: 0.1443\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71267\n",
            "Epoch 7/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7930 - accuracy: 0.1604 - val_loss: 1.7917 - val_accuracy: 0.1430\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71267\n",
            "Epoch 8/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7927 - accuracy: 0.1679 - val_loss: 1.7916 - val_accuracy: 0.1477\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71267\n",
            "Epoch 9/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7931 - accuracy: 0.1630 - val_loss: 1.7916 - val_accuracy: 0.1490\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71267\n",
            "Epoch 10/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7928 - accuracy: 0.1598 - val_loss: 1.7916 - val_accuracy: 0.1467\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71267\n",
            "Epoch 11/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7922 - accuracy: 0.1664 - val_loss: 1.7915 - val_accuracy: 0.1487\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71267\n",
            "Epoch 12/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7925 - accuracy: 0.1698 - val_loss: 1.7915 - val_accuracy: 0.1573\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71267\n",
            "Epoch 13/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7918 - accuracy: 0.1671 - val_loss: 1.7914 - val_accuracy: 0.1633\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71267\n",
            "Epoch 14/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7919 - accuracy: 0.1759 - val_loss: 1.7914 - val_accuracy: 0.1670\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.71267\n",
            "Epoch 15/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7921 - accuracy: 0.1597 - val_loss: 1.7914 - val_accuracy: 0.1693\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.71267\n",
            "Epoch 16/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7910 - accuracy: 0.1707 - val_loss: 1.7913 - val_accuracy: 0.1730\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71267\n",
            "Epoch 17/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7912 - accuracy: 0.1606 - val_loss: 1.7913 - val_accuracy: 0.1817\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.71267\n",
            "Epoch 18/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7919 - accuracy: 0.1630 - val_loss: 1.7913 - val_accuracy: 0.1800\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.71267\n",
            "Epoch 19/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7915 - accuracy: 0.1661 - val_loss: 1.7911 - val_accuracy: 0.1840\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.71267\n",
            "Epoch 20/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7911 - accuracy: 0.1670 - val_loss: 1.7911 - val_accuracy: 0.1860\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.71267\n",
            "Epoch 21/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7908 - accuracy: 0.1680 - val_loss: 1.7911 - val_accuracy: 0.1840\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.71267\n",
            "Epoch 22/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7910 - accuracy: 0.1698 - val_loss: 1.7910 - val_accuracy: 0.1857\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.71267\n",
            "Epoch 23/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7911 - accuracy: 0.1674 - val_loss: 1.7910 - val_accuracy: 0.1870\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.71267\n",
            "Epoch 24/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7912 - accuracy: 0.1624 - val_loss: 1.7910 - val_accuracy: 0.1857\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.71267\n",
            "Epoch 25/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7913 - accuracy: 0.1607 - val_loss: 1.7910 - val_accuracy: 0.1870\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.71267\n",
            "Epoch 26/75\n",
            "439/439 [==============================] - 22s 50ms/step - loss: 1.7909 - accuracy: 0.1686 - val_loss: 1.7909 - val_accuracy: 0.1880\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.71267\n",
            "Epoch 27/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7905 - accuracy: 0.1685 - val_loss: 1.7908 - val_accuracy: 0.1880\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.71267\n",
            "Epoch 28/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7904 - accuracy: 0.1734 - val_loss: 1.7908 - val_accuracy: 0.1910\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.71267\n",
            "Epoch 29/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7904 - accuracy: 0.1691 - val_loss: 1.7908 - val_accuracy: 0.1887\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.71267\n",
            "Epoch 30/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7898 - accuracy: 0.1743 - val_loss: 1.7908 - val_accuracy: 0.1903\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.71267\n",
            "Epoch 31/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7910 - accuracy: 0.1648 - val_loss: 1.7907 - val_accuracy: 0.1920\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.71267\n",
            "Epoch 32/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7907 - accuracy: 0.1641 - val_loss: 1.7906 - val_accuracy: 0.1907\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.71267\n",
            "Epoch 33/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7901 - accuracy: 0.1672 - val_loss: 1.7907 - val_accuracy: 0.1910\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.71267\n",
            "Epoch 34/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7906 - accuracy: 0.1668 - val_loss: 1.7906 - val_accuracy: 0.1923\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.71267\n",
            "Epoch 35/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7892 - accuracy: 0.1786 - val_loss: 1.7906 - val_accuracy: 0.1967\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.71267\n",
            "Epoch 36/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7894 - accuracy: 0.1705 - val_loss: 1.7905 - val_accuracy: 0.1970\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.71267\n",
            "Epoch 37/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7897 - accuracy: 0.1740 - val_loss: 1.7905 - val_accuracy: 0.1990\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.71267\n",
            "Epoch 38/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7890 - accuracy: 0.1782 - val_loss: 1.7905 - val_accuracy: 0.1973\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.71267\n",
            "Epoch 39/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7906 - accuracy: 0.1616 - val_loss: 1.7904 - val_accuracy: 0.2030\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.71267\n",
            "Epoch 40/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7889 - accuracy: 0.1790 - val_loss: 1.7903 - val_accuracy: 0.2000\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.71267\n",
            "Epoch 41/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7893 - accuracy: 0.1689 - val_loss: 1.7903 - val_accuracy: 0.2053\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.71267\n",
            "Epoch 42/75\n",
            "439/439 [==============================] - 25s 57ms/step - loss: 1.7894 - accuracy: 0.1715 - val_loss: 1.7903 - val_accuracy: 0.2047\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.71267\n",
            "Epoch 43/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7892 - accuracy: 0.1728 - val_loss: 1.7903 - val_accuracy: 0.2080\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.71267\n",
            "Epoch 44/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7893 - accuracy: 0.1731 - val_loss: 1.7902 - val_accuracy: 0.2140\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.71267\n",
            "Epoch 45/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7891 - accuracy: 0.1753 - val_loss: 1.7902 - val_accuracy: 0.2137\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.71267\n",
            "Epoch 46/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7903 - accuracy: 0.1678 - val_loss: 1.7902 - val_accuracy: 0.2143\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.71267\n",
            "Epoch 47/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7891 - accuracy: 0.1730 - val_loss: 1.7901 - val_accuracy: 0.2187\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.71267\n",
            "Epoch 48/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7888 - accuracy: 0.1722 - val_loss: 1.7900 - val_accuracy: 0.2160\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.71267\n",
            "Epoch 49/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7888 - accuracy: 0.1714 - val_loss: 1.7901 - val_accuracy: 0.2223\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.71267\n",
            "Epoch 50/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7896 - accuracy: 0.1691 - val_loss: 1.7900 - val_accuracy: 0.2177\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.71267\n",
            "Epoch 51/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7886 - accuracy: 0.1749 - val_loss: 1.7900 - val_accuracy: 0.2233\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.71267\n",
            "Epoch 52/75\n",
            "439/439 [==============================] - 22s 50ms/step - loss: 1.7877 - accuracy: 0.1777 - val_loss: 1.7899 - val_accuracy: 0.2203\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.71267\n",
            "Epoch 53/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7885 - accuracy: 0.1777 - val_loss: 1.7899 - val_accuracy: 0.2233\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.71267\n",
            "Epoch 54/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7873 - accuracy: 0.1849 - val_loss: 1.7899 - val_accuracy: 0.2303\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.71267\n",
            "Epoch 55/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7886 - accuracy: 0.1776 - val_loss: 1.7898 - val_accuracy: 0.2327\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.71267\n",
            "Epoch 56/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7877 - accuracy: 0.1796 - val_loss: 1.7898 - val_accuracy: 0.2293\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.71267\n",
            "Epoch 57/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7872 - accuracy: 0.1801 - val_loss: 1.7898 - val_accuracy: 0.2267\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.71267\n",
            "Epoch 58/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7886 - accuracy: 0.1753 - val_loss: 1.7897 - val_accuracy: 0.2320\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.71267\n",
            "Epoch 59/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7878 - accuracy: 0.1697 - val_loss: 1.7897 - val_accuracy: 0.2330\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.71267\n",
            "Epoch 60/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7881 - accuracy: 0.1747 - val_loss: 1.7897 - val_accuracy: 0.2370\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.71267\n",
            "Epoch 61/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7876 - accuracy: 0.1799 - val_loss: 1.7896 - val_accuracy: 0.2413\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.71267\n",
            "Epoch 62/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7880 - accuracy: 0.1759 - val_loss: 1.7896 - val_accuracy: 0.2403\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.71267\n",
            "Epoch 63/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7879 - accuracy: 0.1722 - val_loss: 1.7895 - val_accuracy: 0.2407\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.71267\n",
            "Epoch 64/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7876 - accuracy: 0.1832 - val_loss: 1.7895 - val_accuracy: 0.2417\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.71267\n",
            "Epoch 65/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7872 - accuracy: 0.1741 - val_loss: 1.7894 - val_accuracy: 0.2400\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.71267\n",
            "Epoch 66/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7865 - accuracy: 0.1830 - val_loss: 1.7895 - val_accuracy: 0.2440\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.71267\n",
            "Epoch 67/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7870 - accuracy: 0.1796 - val_loss: 1.7894 - val_accuracy: 0.2417\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.71267\n",
            "Epoch 68/75\n",
            "439/439 [==============================] - 26s 58ms/step - loss: 1.7877 - accuracy: 0.1786 - val_loss: 1.7894 - val_accuracy: 0.2460\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.71267\n",
            "Epoch 69/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7868 - accuracy: 0.1784 - val_loss: 1.7894 - val_accuracy: 0.2453\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.71267\n",
            "Epoch 70/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7874 - accuracy: 0.1754 - val_loss: 1.7893 - val_accuracy: 0.2457\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.71267\n",
            "Epoch 71/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7873 - accuracy: 0.1805 - val_loss: 1.7892 - val_accuracy: 0.2457\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.71267\n",
            "Epoch 72/75\n",
            "439/439 [==============================] - 26s 59ms/step - loss: 1.7870 - accuracy: 0.1785 - val_loss: 1.7892 - val_accuracy: 0.2567\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.71267\n",
            "Epoch 73/75\n",
            "439/439 [==============================] - 22s 50ms/step - loss: 1.7871 - accuracy: 0.1783 - val_loss: 1.7892 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.71267\n",
            "Epoch 74/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7874 - accuracy: 0.1811 - val_loss: 1.7892 - val_accuracy: 0.2420\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.71267\n",
            "Epoch 75/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7856 - accuracy: 0.1857 - val_loss: 1.7891 - val_accuracy: 0.2533\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.71267\n",
            "SGD\n",
            "Epoch 1/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7984 - accuracy: 0.1551 - val_loss: 1.7929 - val_accuracy: 0.1630\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.71267\n",
            "Epoch 2/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7974 - accuracy: 0.1635 - val_loss: 1.7928 - val_accuracy: 0.1647\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.71267\n",
            "Epoch 3/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7979 - accuracy: 0.1609 - val_loss: 1.7927 - val_accuracy: 0.1637\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.71267\n",
            "Epoch 4/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7970 - accuracy: 0.1645 - val_loss: 1.7927 - val_accuracy: 0.1590\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71267\n",
            "Epoch 5/75\n",
            "439/439 [==============================] - 26s 59ms/step - loss: 1.7975 - accuracy: 0.1614 - val_loss: 1.7926 - val_accuracy: 0.1587\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71267\n",
            "Epoch 6/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7968 - accuracy: 0.1638 - val_loss: 1.7926 - val_accuracy: 0.1590\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71267\n",
            "Epoch 7/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7964 - accuracy: 0.1609 - val_loss: 1.7925 - val_accuracy: 0.1653\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71267\n",
            "Epoch 8/75\n",
            "439/439 [==============================] - 26s 59ms/step - loss: 1.7961 - accuracy: 0.1629 - val_loss: 1.7924 - val_accuracy: 0.1653\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71267\n",
            "Epoch 9/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7960 - accuracy: 0.1607 - val_loss: 1.7925 - val_accuracy: 0.1557\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71267\n",
            "Epoch 10/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7957 - accuracy: 0.1625 - val_loss: 1.7924 - val_accuracy: 0.1520\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71267\n",
            "Epoch 11/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7956 - accuracy: 0.1645 - val_loss: 1.7924 - val_accuracy: 0.1567\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71267\n",
            "Epoch 12/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7961 - accuracy: 0.1653 - val_loss: 1.7922 - val_accuracy: 0.1547\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71267\n",
            "Epoch 13/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7955 - accuracy: 0.1562 - val_loss: 1.7922 - val_accuracy: 0.1503\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71267\n",
            "Epoch 14/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7951 - accuracy: 0.1580 - val_loss: 1.7921 - val_accuracy: 0.1537\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.71267\n",
            "Epoch 15/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7949 - accuracy: 0.1640 - val_loss: 1.7921 - val_accuracy: 0.1510\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.71267\n",
            "Epoch 16/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7942 - accuracy: 0.1724 - val_loss: 1.7921 - val_accuracy: 0.1577\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71267\n",
            "Epoch 17/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7952 - accuracy: 0.1609 - val_loss: 1.7921 - val_accuracy: 0.1483\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.71267\n",
            "Epoch 18/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7953 - accuracy: 0.1636 - val_loss: 1.7920 - val_accuracy: 0.1507\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.71267\n",
            "Epoch 19/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7946 - accuracy: 0.1710 - val_loss: 1.7920 - val_accuracy: 0.1503\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.71267\n",
            "Epoch 20/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7949 - accuracy: 0.1640 - val_loss: 1.7919 - val_accuracy: 0.1583\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.71267\n",
            "Epoch 21/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7939 - accuracy: 0.1655 - val_loss: 1.7919 - val_accuracy: 0.1527\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.71267\n",
            "Epoch 22/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7945 - accuracy: 0.1604 - val_loss: 1.7919 - val_accuracy: 0.1523\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.71267\n",
            "Epoch 23/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7937 - accuracy: 0.1701 - val_loss: 1.7918 - val_accuracy: 0.1553\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.71267\n",
            "Epoch 24/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7933 - accuracy: 0.1653 - val_loss: 1.7917 - val_accuracy: 0.1473\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.71267\n",
            "Epoch 25/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7936 - accuracy: 0.1587 - val_loss: 1.7917 - val_accuracy: 0.1510\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.71267\n",
            "Epoch 26/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7935 - accuracy: 0.1636 - val_loss: 1.7916 - val_accuracy: 0.1540\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.71267\n",
            "Epoch 27/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7933 - accuracy: 0.1633 - val_loss: 1.7917 - val_accuracy: 0.1447\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.71267\n",
            "Epoch 28/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7931 - accuracy: 0.1680 - val_loss: 1.7916 - val_accuracy: 0.1520\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.71267\n",
            "Epoch 29/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7929 - accuracy: 0.1665 - val_loss: 1.7916 - val_accuracy: 0.1533\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.71267\n",
            "Epoch 30/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7933 - accuracy: 0.1641 - val_loss: 1.7915 - val_accuracy: 0.1517\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.71267\n",
            "Epoch 31/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7939 - accuracy: 0.1527 - val_loss: 1.7914 - val_accuracy: 0.1530\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.71267\n",
            "Epoch 32/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7933 - accuracy: 0.1624 - val_loss: 1.7914 - val_accuracy: 0.1503\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.71267\n",
            "Epoch 33/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7931 - accuracy: 0.1679 - val_loss: 1.7915 - val_accuracy: 0.1470\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.71267\n",
            "Epoch 34/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7933 - accuracy: 0.1597 - val_loss: 1.7914 - val_accuracy: 0.1530\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.71267\n",
            "Epoch 35/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7927 - accuracy: 0.1633 - val_loss: 1.7913 - val_accuracy: 0.1617\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.71267\n",
            "Epoch 36/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7928 - accuracy: 0.1672 - val_loss: 1.7913 - val_accuracy: 0.1607\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.71267\n",
            "Epoch 37/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 1.7921 - accuracy: 0.1714 - val_loss: 1.7913 - val_accuracy: 0.1510\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.71267\n",
            "Epoch 38/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7924 - accuracy: 0.1677 - val_loss: 1.7913 - val_accuracy: 0.1630\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.71267\n",
            "Epoch 39/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7923 - accuracy: 0.1690 - val_loss: 1.7912 - val_accuracy: 0.1713\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.71267\n",
            "Epoch 40/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7926 - accuracy: 0.1653 - val_loss: 1.7913 - val_accuracy: 0.1697\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.71267\n",
            "Epoch 41/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7918 - accuracy: 0.1687 - val_loss: 1.7912 - val_accuracy: 0.1787\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.71267\n",
            "Epoch 42/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7917 - accuracy: 0.1670 - val_loss: 1.7912 - val_accuracy: 0.1773\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.71267\n",
            "Epoch 43/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7919 - accuracy: 0.1699 - val_loss: 1.7911 - val_accuracy: 0.1850\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.71267\n",
            "Epoch 44/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7915 - accuracy: 0.1707 - val_loss: 1.7911 - val_accuracy: 0.1910\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.71267\n",
            "Epoch 45/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7917 - accuracy: 0.1690 - val_loss: 1.7911 - val_accuracy: 0.1887\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.71267\n",
            "Epoch 46/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7921 - accuracy: 0.1689 - val_loss: 1.7910 - val_accuracy: 0.1970\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.71267\n",
            "Epoch 47/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7912 - accuracy: 0.1679 - val_loss: 1.7910 - val_accuracy: 0.1977\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.71267\n",
            "Epoch 48/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7917 - accuracy: 0.1631 - val_loss: 1.7910 - val_accuracy: 0.2020\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.71267\n",
            "Epoch 49/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7915 - accuracy: 0.1689 - val_loss: 1.7909 - val_accuracy: 0.2040\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.71267\n",
            "Epoch 50/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7916 - accuracy: 0.1694 - val_loss: 1.7909 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.71267\n",
            "Epoch 51/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7910 - accuracy: 0.1730 - val_loss: 1.7908 - val_accuracy: 0.2103\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.71267\n",
            "Epoch 52/75\n",
            "439/439 [==============================] - 22s 51ms/step - loss: 1.7917 - accuracy: 0.1657 - val_loss: 1.7908 - val_accuracy: 0.2010\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.71267\n",
            "Epoch 53/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7913 - accuracy: 0.1690 - val_loss: 1.7908 - val_accuracy: 0.2170\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.71267\n",
            "Epoch 54/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7913 - accuracy: 0.1690 - val_loss: 1.7908 - val_accuracy: 0.2197\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.71267\n",
            "Epoch 55/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7916 - accuracy: 0.1714 - val_loss: 1.7907 - val_accuracy: 0.2133\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.71267\n",
            "Epoch 56/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7906 - accuracy: 0.1656 - val_loss: 1.7908 - val_accuracy: 0.2133\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.71267\n",
            "Epoch 57/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7913 - accuracy: 0.1716 - val_loss: 1.7907 - val_accuracy: 0.2147\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.71267\n",
            "Epoch 58/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7911 - accuracy: 0.1671 - val_loss: 1.7906 - val_accuracy: 0.2150\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.71267\n",
            "Epoch 59/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7907 - accuracy: 0.1657 - val_loss: 1.7906 - val_accuracy: 0.2153\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.71267\n",
            "Epoch 60/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7906 - accuracy: 0.1685 - val_loss: 1.7906 - val_accuracy: 0.2103\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.71267\n",
            "Epoch 61/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7899 - accuracy: 0.1756 - val_loss: 1.7906 - val_accuracy: 0.2193\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.71267\n",
            "Epoch 62/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7897 - accuracy: 0.1751 - val_loss: 1.7906 - val_accuracy: 0.2177\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.71267\n",
            "Epoch 63/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7902 - accuracy: 0.1687 - val_loss: 1.7905 - val_accuracy: 0.2227\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.71267\n",
            "Epoch 64/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7906 - accuracy: 0.1693 - val_loss: 1.7905 - val_accuracy: 0.2177\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.71267\n",
            "Epoch 65/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7905 - accuracy: 0.1690 - val_loss: 1.7906 - val_accuracy: 0.2253\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.71267\n",
            "Epoch 66/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7902 - accuracy: 0.1726 - val_loss: 1.7904 - val_accuracy: 0.2253\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.71267\n",
            "Epoch 67/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7904 - accuracy: 0.1742 - val_loss: 1.7904 - val_accuracy: 0.2217\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.71267\n",
            "Epoch 68/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7898 - accuracy: 0.1715 - val_loss: 1.7904 - val_accuracy: 0.2280\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.71267\n",
            "Epoch 69/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7897 - accuracy: 0.1729 - val_loss: 1.7904 - val_accuracy: 0.2230\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.71267\n",
            "Epoch 70/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7901 - accuracy: 0.1701 - val_loss: 1.7903 - val_accuracy: 0.2293\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.71267\n",
            "Epoch 71/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7890 - accuracy: 0.1784 - val_loss: 1.7903 - val_accuracy: 0.2210\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.71267\n",
            "Epoch 72/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7899 - accuracy: 0.1724 - val_loss: 1.7903 - val_accuracy: 0.2287\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.71267\n",
            "Epoch 73/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7898 - accuracy: 0.1716 - val_loss: 1.7903 - val_accuracy: 0.2223\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.71267\n",
            "Epoch 74/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 1.7891 - accuracy: 0.1759 - val_loss: 1.7902 - val_accuracy: 0.2330\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.71267\n",
            "Epoch 75/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7904 - accuracy: 0.1705 - val_loss: 1.7903 - val_accuracy: 0.2273\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.71267\n",
            "SGD\n",
            "Epoch 1/75\n",
            "439/439 [==============================] - 24s 53ms/step - loss: 1.7944 - accuracy: 0.1746 - val_loss: 1.7920 - val_accuracy: 0.1873\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.71267\n",
            "Epoch 2/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7944 - accuracy: 0.1763 - val_loss: 1.7920 - val_accuracy: 0.1923\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.71267\n",
            "Epoch 3/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7946 - accuracy: 0.1688 - val_loss: 1.7919 - val_accuracy: 0.2003\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.71267\n",
            "Epoch 4/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7936 - accuracy: 0.1710 - val_loss: 1.7919 - val_accuracy: 0.1937\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71267\n",
            "Epoch 5/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7928 - accuracy: 0.1757 - val_loss: 1.7919 - val_accuracy: 0.1953\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71267\n",
            "Epoch 6/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7926 - accuracy: 0.1794 - val_loss: 1.7919 - val_accuracy: 0.2017\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71267\n",
            "Epoch 7/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7933 - accuracy: 0.1769 - val_loss: 1.7918 - val_accuracy: 0.2040\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71267\n",
            "Epoch 8/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7935 - accuracy: 0.1717 - val_loss: 1.7917 - val_accuracy: 0.2020\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71267\n",
            "Epoch 9/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7928 - accuracy: 0.1774 - val_loss: 1.7917 - val_accuracy: 0.1957\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71267\n",
            "Epoch 10/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7930 - accuracy: 0.1733 - val_loss: 1.7916 - val_accuracy: 0.1940\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71267\n",
            "Epoch 11/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7938 - accuracy: 0.1691 - val_loss: 1.7916 - val_accuracy: 0.1960\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71267\n",
            "Epoch 12/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7922 - accuracy: 0.1742 - val_loss: 1.7916 - val_accuracy: 0.1880\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71267\n",
            "Epoch 13/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7928 - accuracy: 0.1712 - val_loss: 1.7915 - val_accuracy: 0.1920\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71267\n",
            "Epoch 14/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7926 - accuracy: 0.1672 - val_loss: 1.7914 - val_accuracy: 0.1927\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.71267\n",
            "Epoch 15/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7929 - accuracy: 0.1743 - val_loss: 1.7914 - val_accuracy: 0.1897\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.71267\n",
            "Epoch 16/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 1.7925 - accuracy: 0.1700 - val_loss: 1.7913 - val_accuracy: 0.1830\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71267\n",
            "Epoch 17/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7922 - accuracy: 0.1705 - val_loss: 1.7914 - val_accuracy: 0.1833\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.71267\n",
            "Epoch 18/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7916 - accuracy: 0.1792 - val_loss: 1.7913 - val_accuracy: 0.1830\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.71267\n",
            "Epoch 19/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7916 - accuracy: 0.1734 - val_loss: 1.7912 - val_accuracy: 0.1833\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.71267\n",
            "Epoch 20/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7914 - accuracy: 0.1756 - val_loss: 1.7913 - val_accuracy: 0.1823\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.71267\n",
            "Epoch 21/75\n",
            "439/439 [==============================] - 23s 51ms/step - loss: 1.7912 - accuracy: 0.1775 - val_loss: 1.7912 - val_accuracy: 0.1803\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.71267\n",
            "Epoch 22/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7922 - accuracy: 0.1761 - val_loss: 1.7912 - val_accuracy: 0.1820\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.71267\n",
            "Epoch 23/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7910 - accuracy: 0.1814 - val_loss: 1.7911 - val_accuracy: 0.1783\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.71267\n",
            "Epoch 24/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7912 - accuracy: 0.1809 - val_loss: 1.7910 - val_accuracy: 0.1787\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.71267\n",
            "Epoch 25/75\n",
            "439/439 [==============================] - 23s 52ms/step - loss: 1.7912 - accuracy: 0.1781 - val_loss: 1.7910 - val_accuracy: 0.1850\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.71267\n",
            "Epoch 26/75\n",
            "439/439 [==============================] - 23s 53ms/step - loss: 1.7911 - accuracy: 0.1754 - val_loss: 1.7911 - val_accuracy: 0.1797\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.71267\n",
            "Epoch 27/75\n",
            "196/439 [============>.................] - ETA: 10s - loss: 1.7910 - accuracy: 0.1801Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0gEwgTgj3ZU"
      },
      "source": [
        "<h2> Evaluate the Model </h2>\r\n",
        "Model is evaluated on the weights that produced the highest validation accuracy. These weights were stored during training.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4x1msUSvyEx",
        "outputId": "16880502-a1dd-4d87-86b1-7fdb4cb37f10"
      },
      "source": [
        "\r\n",
        "saved_model = load_model('CheckPoints/VGG-like-Aug-model.h5')\r\n",
        "# evaluate the model\r\n",
        "_, train_acc = saved_model.evaluate_generator(train_generator, verbose=0)\r\n",
        "_, val_acc = saved_model.evaluate_generator(validate_generator, verbose=0)\r\n",
        "_, test_acc = saved_model.evaluate_generator(test_generator, verbose=0)\r\n",
        "print('Train: %.3f,Val: %.3f, Test: %.3f' % (train_acc, val_acc,  test_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 0.706,Val: 0.703, Test: 0.704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v95l9dZ4kIj5"
      },
      "source": [
        "<h2> Plotting Training and Validation accuracy of different optimizers </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eccYegnUIJrM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "de34a4cd-3e6d-4d0c-c792-51489f4c579e"
      },
      "source": [
        "\r\n",
        "History =0\r\n",
        "History = History2\r\n",
        "acc = History.history['accuracy']\r\n",
        "val_acc = History.history['val_accuracy']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.xlabel('Epochs (Early Stopping)')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.title('VGG16 Accuracy')\r\n",
        "\r\n",
        "plt.plot(epochs, acc, label='Adam Training acc')\r\n",
        "plt.plot(epochs, val_acc, label='Adam Validation acc')\r\n",
        "\r\n",
        "History =0\r\n",
        "History = History4\r\n",
        "acc = History.history['accuracy']\r\n",
        "val_acc = History.history['val_accuracy']\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, label='SGD Training acc')\r\n",
        "plt.plot(epochs, val_acc, label='SGD Validation acc')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "History =0\r\n",
        "History = History7\r\n",
        "acc = History.history['accuracy']\r\n",
        "val_acc = History.history['val_accuracy']\r\n",
        "epochs = range(len(acc))\r\n",
        "plt.plot(epochs, acc, label='RMS Training acc')\r\n",
        "plt.plot(epochs, val_acc, label='RMS Validation acc')\r\n",
        "plt.legend()\r\n",
        "plt.savefig(\"Results/DataAugVGG16Historyacc.png\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc2fc35d048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qJL0nnDqgdQ"
      },
      "source": [
        "<h2> Plotting Training and Validation losses of different optimizers </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Iq6mchm4JdiX",
        "outputId": "712d7a5e-a231-48ff-f19e-f4ac81744e9c"
      },
      "source": [
        "\r\n",
        "History =0\r\n",
        "History = History3\r\n",
        "loss = History.history['loss']\r\n",
        "val_loss = History.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(loss))\r\n",
        "plt.xlabel('Epochs (Early Stopping)')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.title('VGG16 Losses')\r\n",
        "\r\n",
        "plt.plot(epochs, loss, label='Adam Training loss')\r\n",
        "plt.plot(epochs, val_loss, label='Adam Validation loss')\r\n",
        "\r\n",
        "History =0\r\n",
        "History = History5\r\n",
        "loss = History.history['loss']\r\n",
        "val_loss = History.history['val_loss']\r\n",
        "epochs = range(len(loss))\r\n",
        "plt.plot(epochs, loss, label='SGD Training loss')\r\n",
        "plt.plot(epochs, val_loss, label='SGD Validation loss')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "History =0\r\n",
        "History = History7\r\n",
        "loss = History.history['loss']\r\n",
        "val_loss = History.history['val_loss']\r\n",
        "epochs = range(len(loss))\r\n",
        "plt.plot(epochs, loss, label='RMS Training loss')\r\n",
        "plt.plot(epochs, val_loss, label='RMS Validation loss')\r\n",
        "plt.legend()\r\n",
        "plt.savefig(\"Results/DataAugVGG16Historyloss.png\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc2fc558fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY2tOJ0Kkdrx"
      },
      "source": [
        "<h2> Predict on Unseen Images </h2>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "680ScwhP_Oiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbd870f-0e28-439e-9bfd-f8f7e80d051e"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "saved_model = load_model('CheckPoints/VGG-like-Aug-model.h5')\r\n",
        "predY = saved_model.predict_generator(test_generator)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ckzr_gqlo0"
      },
      "source": [
        "<h2> Confusion Matrix </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEw5Qlu0sSSM",
        "outputId": "cafdd6f9-c08a-42f4-9927-49dd879eb345"
      },
      "source": [
        "\r\n",
        "predY_classes = predY.argmax(1)\r\n",
        "confusion_matrix = pd.crosstab(test_generator.classes, predY_classes,margins=True)\r\n",
        "print(\"Confusion matrix:\\n%s\" % confusion_matrix)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "col_0    0     1     2     3     4     5   All\n",
            "row_0                                         \n",
            "0      106   271   218   193   173   183  1144\n",
            "1      125   283   198   210   169   181  1166\n",
            "2      113   344   233   226   202   212  1330\n",
            "3      117   311   229   263   183   194  1297\n",
            "4      108   272   196   225   149   178  1128\n",
            "5      131   285   227   213   189   191  1236\n",
            "All    700  1766  1301  1330  1065  1139  7301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "bF6VlT26_E4p",
        "outputId": "df5b28ca-6bbf-4142-8b71-b7a85c7266d6"
      },
      "source": [
        "def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.YlOrRd):\r\n",
        "  plt.matshow(df_confusion) # imshow\r\n",
        "  plt.colorbar()\r\n",
        "  tick_marks = np.arange(len(df_confusion.columns))\r\n",
        "  plt.xticks(tick_marks, df_confusion.columns, rotation=45)\r\n",
        "  plt.yticks(tick_marks, df_confusion.index)\r\n",
        "  plt.ylabel(\"Actual\")\r\n",
        "  plt.xlabel(\"Predicted\")\r\n",
        "  plt.savefig(\"Results/DataAugVGG16Augconfusion.jpg\")\r\n",
        "#call function\r\n",
        "plot_confusion_matrix(confusion_matrix)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}